{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b11994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import spynnaker8 as sim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "import field_encoding as fe\n",
    "from field_encoding import ROWS_AS_MSB\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2773d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(start_char, n_digits, n_test=10000, scale=1.0):\n",
    "\n",
    "    most_significant_rows = ROWS_AS_MSB\n",
    "\n",
    "    filename = \"simple_cnn_network_elements.npz\"\n",
    "\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    thresholds = dict(\n",
    "        conv2d=1,#3.1836495399475098,\n",
    "        conv2d_1=1,#2.9346282482147217,\n",
    "        dense=1,#1.1361589431762695,\n",
    "        dense_1=1,#2.435835599899292,\n",
    "        dense_2=1,#2.36885929107666,\n",
    "    )\n",
    "\n",
    "    order0 = data['order']\n",
    "    order = order0[:]\n",
    "    ml_conns = data['conns'].item()\n",
    "    ml_param = data['params'].item()\n",
    "\n",
    "    # print(list(data.keys()))\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "#     random_state = check_random_state(0)\n",
    "#     permutation = random_state.permutation(X.shape[0])\n",
    "#     X = X[permutation]\n",
    "#     y = y[permutation]\n",
    "    X = X.reshape((X.shape[0], -1))\n",
    "    \n",
    "    train_samples = 5000\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                X, y, train_size=train_samples, test_size=10000)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_X_0 = X_test[start_char: start_char + n_digits]\n",
    "    test_y = y_test[start_char: start_char + n_digits]\n",
    "    \n",
    "    shape_in = np.asarray([64, 64])\n",
    "    orig_shape = [28, 28]\n",
    "    test_X = []\n",
    "    for i, x in enumerate(test_X_0):\n",
    "#         image_resized = resize(image, (image.shape[0] // 4, image.shape[1] // 4),\n",
    "#                        anti_aliasing=True)\n",
    "        x = x.reshape(orig_shape)\n",
    "        x = resize(x, shape_in, anti_aliasing=True)\n",
    "        test_X.append(x)\n",
    "        \n",
    "    # shape of dataset\n",
    "    # print('X_test:  ' + str(test_X.shape))\n",
    "    # print('Y_test:  ' + str(test_y.shape))\n",
    "\n",
    "    # plotting\n",
    "    # for i in range(9):\n",
    "    #     plt.subplot(330 + 1 + i)\n",
    "    #     plt.imshow(test_X[i], cmap=plt.get_cmap('gray'))\n",
    "    #\n",
    "    # plt.show()\n",
    "\n",
    "    MAX_N_DENSE = 64\n",
    "    MAX_N_CONV = 512\n",
    "    # sim.extra_models.SpikeSourcePoissonVariable.set_model_max_atoms_per_core(512)\n",
    "    sim.IF_curr_exp_conv.set_model_max_atoms_per_core(MAX_N_CONV)\n",
    "    sim.NIF_curr_exp_conv.set_model_max_atoms_per_core(MAX_N_CONV)\n",
    "    # sim.IF_curr_exp_conv.set_model_max_atoms_per_core(n_atoms=256)\n",
    "    sim.IF_curr_exp_pool_dense.set_model_max_atoms_per_core(MAX_N_DENSE)\n",
    "    sim.NIF_curr_exp_pool_dense.set_model_max_atoms_per_core(MAX_N_DENSE)\n",
    "\n",
    "    sim.setup(timestep=1.)\n",
    "\n",
    "    np.random.seed(13)\n",
    "\n",
    "    # shapes are specified as Height, Width == Rows, Columns\n",
    "    n_in = int(np.prod(shape_in))\n",
    "    in_ids = np.arange(0, n_in)\n",
    "    n_in = fe.max_coord_size(shape=shape_in, most_significant_rows=ROWS_AS_MSB)\n",
    "    xy_in_ids = fe.convert_ids(in_ids, shape=shape_in, most_significant_rows=ROWS_AS_MSB)\n",
    "\n",
    "    digit_duration = 500.0  # ms\n",
    "    digit_rate = 100.0  # hz\n",
    "    in_rates = np.zeros((n_in, n_digits))\n",
    "    for i in range(n_digits):\n",
    "        in_rates[xy_in_ids, i] = test_X[i].flatten()\n",
    "\n",
    "    in_rates *= (digit_rate / in_rates.max())\n",
    "    in_durations = np.ones((n_in, n_digits)) * np.round(digit_duration * 0.9)\n",
    "    in_starts = np.repeat([np.arange(n_digits) * digit_duration],\n",
    "                          n_in, axis=0)\n",
    "    in_params = {\n",
    "        'rates': in_rates,\n",
    "        'starts': in_starts,\n",
    "        'durations': in_durations\n",
    "    }\n",
    "    pops = {\n",
    "        'input': [sim.Population(  # put into list for ease of connection\n",
    "            n_in,  # number of sources\n",
    "            sim.extra_models.SpikeSourcePoissonVariable,  # source type\n",
    "            in_params,\n",
    "            label='mnist',\n",
    "            additional_parameters={'seed': 24534}\n",
    "        )]\n",
    "    }\n",
    "    sizes = {'input': [p.size for p in pops['input']]}\n",
    "\n",
    "    # ------------------------------------------------------------------- #\n",
    "    # ------------------------------------------------------------------- #\n",
    "    def_params = {\n",
    "        'v_thresh': 1.,\n",
    "        'v_reset': 0.,\n",
    "        'v': 0.,\n",
    "        # 'v_rest': 0.,\n",
    "        # 'tau_m': 10.,\n",
    "        # 'cm': 0.80,\n",
    "    }\n",
    "    local_thresh = bool(0)\n",
    "    use_lif = bool(0)\n",
    "    conv_cell_type = sim.IF_curr_exp_conv if use_lif else sim.NIF_curr_exp_conv\n",
    "    dense_cell_type = sim.IF_curr_exp_pool_dense if use_lif else sim.NIF_curr_exp_pool_dense\n",
    "    pre_shapes = [np.array([28, 28])]\n",
    "    for i, o in enumerate(order):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        o0 = order[i - 1]\n",
    "        pre_shape = pre_shapes[i - 1]\n",
    "        par = ml_param[o]\n",
    "        if 'conv2d' in o.lower():\n",
    "            c = ml_conns[o]\n",
    "            kernel_shape = c['weights'].shape[:2]\n",
    "            pooling = 'pool' in c\n",
    "            pool_area = np.asarray(c['pool']['shape']) if pooling else None\n",
    "            pool_stride = np.asarray(c['pool']['strides']) if pooling else None\n",
    "            wshape = c.get('shape', None)\n",
    "            strides = c.get('strides', None)\n",
    "            shape = sim.ConvolutionConnector.calculate_post_shape(\n",
    "                            pre_shape, kernel_shape, \n",
    "                            padding=np.array([0, 0]), \n",
    "                            stride=strides, \n",
    "                            pooling=pooling, \n",
    "                            pool_shape=pool_area, \n",
    "                            pool_stride=pool_stride)\n",
    "            pre_shapes.append(shape)\n",
    "            \n",
    "#             shape = par['shape'][0:2]\n",
    "            chans = par['shape'][2]\n",
    "            ps = def_params.copy()\n",
    "            v = ps.pop('v')\n",
    "            ps['v_thresh'] = thresholds[o] if local_thresh else par['threshold']\n",
    "            n = int(np.prod(shape))\n",
    "            n = fe.max_coord_size(shape=shape, most_significant_rows=ROWS_AS_MSB)\n",
    "            # print(o, n, shape, chans)\n",
    "            pop = [sim.Population(n, conv_cell_type, ps,\n",
    "                                  label=\"{}_chan_{}\".format(o, ch))\n",
    "                   for ch in range(chans)]\n",
    "\n",
    "            for p in pop:\n",
    "                p.set(v=v)\n",
    "        elif 'dense' in o.lower():\n",
    "            shape = par['shape'][0:2]\n",
    "            pre_shapes.append(shape)\n",
    "            ps = def_params.copy()\n",
    "            v = ps.pop('v')\n",
    "            ps['v_thresh'] = thresholds[o] if local_thresh else par['threshold']\n",
    "\n",
    "            # TODO: should this be converted to XY encoding as well?\n",
    "            #       at this point I think any topology is lost\n",
    "            n = int(np.prod(shape))\n",
    "            chans = 1\n",
    "            # TODO: Before I was manually splitting the flatten / dense\n",
    "            #       region. Hopefully, with the automatic splitting, we can\n",
    "            #       get all the network to fit in the small board\n",
    "            # if 'conv2d' in order[i-1]:\n",
    "            #     chans = 4\n",
    "            #     n = n // chans\n",
    "\n",
    "            pop = [sim.Population(n, dense_cell_type, ps,\n",
    "                                  label=\"{}_chan_{}\".format(o, ch))\n",
    "                   for ch in range(chans)]\n",
    "            for p in pop:\n",
    "                p.set(v=v)\n",
    "\n",
    "        sizes[o] = [p.size for p in pop]\n",
    "        pops[o] = pop\n",
    "\n",
    "    rec = [\n",
    "        'input',\n",
    "        'conv2d',\n",
    "        'conv2d_1',\n",
    "        'dense',\n",
    "        'dense_1',\n",
    "        'dense_2',\n",
    "    ]\n",
    "\n",
    "    shapes = {\n",
    "        'input': [28, 28],\n",
    "        'conv2d': [24, 24],\n",
    "        'conv2d_1': [8, 8],\n",
    "        'dense': [12, 12],\n",
    "        'dense_1': [8, 8],\n",
    "        'dense_2': [4, 4],\n",
    "    }\n",
    "\n",
    "    offsets = {\n",
    "        'input': 0,\n",
    "        'conv2d': 0,\n",
    "        'conv2d_1': 0,\n",
    "        'dense': 32,\n",
    "        'dense_1': 0,\n",
    "        'dense_2': 0,\n",
    "    }\n",
    "\n",
    "    for k in rec:\n",
    "        for p in pops[k][:]:\n",
    "            p.record('spikes')\n",
    "\n",
    "    projs = {}\n",
    "    kernels = {}\n",
    "    dense_weights = {}\n",
    "\n",
    "    def norm_w(w, is_conv=False, trans=None):\n",
    "        new_w = w.copy()\n",
    "        if trans == 'linear':\n",
    "            max_w = np.max(np.abs(w))\n",
    "            new_w /= max_w\n",
    "        elif trans == 'sum_to_0':\n",
    "            pos = w[w > 0]\n",
    "            pos /= np.sum(pos)\n",
    "            neg = w[w < 0]\n",
    "            neg /= (-np.sum(neg))\n",
    "            new_w = w.copy()\n",
    "            new_w[w > 0] = pos\n",
    "            new_w[w < 0] = neg\n",
    "        elif trans == 'mean_var':\n",
    "            v = new_w.var()\n",
    "            new_w -= new_w.mean()\n",
    "            new_w /= v\n",
    "\n",
    "        return new_w\n",
    "\n",
    "\n",
    "    for i, o in enumerate(order):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        c = ml_conns[o]\n",
    "        weights = c['weights']\n",
    "        pooling = 'pool' in c\n",
    "        pool_area = np.asarray(c['pool']['shape']) if pooling else None\n",
    "        pool_stride = np.asarray(c['pool']['strides']) if pooling else None\n",
    "        wshape = c.get('shape', None)\n",
    "        strides = c.get('strides', None)\n",
    "        pre_shape = pre_shapes[i - 1]\n",
    "        o0 = order[i - 1]\n",
    "        # dense_weights[o] =\n",
    "        pops0 = pops[o0]\n",
    "        pops1 = pops[o]\n",
    "        # print(o0, o)\n",
    "        for prei, pre in enumerate(pops0):\n",
    "#             pre_shape = np.asarray(ml_param[o0]['shape'][:2])\n",
    "\n",
    "            if len(pre_shape) == 1:\n",
    "                pre_shape = (1, pre.size)\n",
    "                n_chan = 1\n",
    "            else:\n",
    "                n_chan = ml_param[o0]['shape'][-1]\n",
    "\n",
    "            wl = []\n",
    "            for posti, post in enumerate(pops1):\n",
    "                lbl = \"{}_{} to {}_{}\".format(o0, prei, o, posti)\n",
    "                # print(pre_shape, n_chan, o0, prei, o, posti)\n",
    "                if 'conv2d' in o.lower():\n",
    "                    # print(prei, posti, wshape, c['weights'].shape)\n",
    "                    w = norm_w(weights[:, :, prei, posti].copy())\n",
    "                    # note we need to flip kernels for the operation to be a\n",
    "                    # convolution instead of a correlation\n",
    "                    w = np.flipud(np.fliplr(w))\n",
    "                    wl.append(w)\n",
    "                    cn = sim.ConvolutionConnector(pre_shape, w, strides=strides,\n",
    "                            pooling=pool_area, pool_stride=pool_stride,\n",
    "                            most_significant_rows=most_significant_rows)\n",
    "                    prj = sim.Projection(pre, post, cn, label=lbl)\n",
    "                    projs[lbl] = prj\n",
    "\n",
    "                elif 'dense' in o.lower():\n",
    "                    n_out = post.size\n",
    "                    sh_pre = sim.PoolDenseConnector.calc_post_pool_shape(\n",
    "                                pre_shape, pooling, pool_area, pool_stride)\n",
    "                    size_pre = int(np.prod(sh_pre))\n",
    "                    if 'conv2d' in o0.lower():\n",
    "                        pre_is_conv = True\n",
    "                        cnv = pops[o0]\n",
    "                        col0 = posti * n_out\n",
    "                        col1 = col0 + n_out\n",
    "\n",
    "                        mtx_rows = []\n",
    "                        chan = prei\n",
    "                        for r in np.arange(sh_pre[0]):\n",
    "                            for c in np.arange(sh_pre[1]):\n",
    "                                mtx_rows.append(r * sh_pre[1] * len(pops[o0]) +\n",
    "                                                c * len(pops[o0]) + chan)\n",
    "                        mtx_rows = np.asarray(mtx_rows)\n",
    "                        pre_rows = np.repeat(np.arange(sh_pre[0]), sh_pre[1])\n",
    "                        # print(\"pre_rows = {}\".format(pre_rows))\n",
    "                        pre_cols = np.tile(np.arange(sh_pre[1]), sh_pre[0])\n",
    "                        # print(\"pre_cols = {}\".format(pre_cols))\n",
    "                        mtx_rows0 = (pre_rows * sh_pre[1] * n_chan +\n",
    "                                     pre_cols * n_chan + prei)\n",
    "                        # print(\"mtx_rows = {}\".format(mtx_rows))\n",
    "                        # print(np.all(mtx_rows == mtx_rows0))\n",
    "                        n_rows = len(mtx_rows)\n",
    "                        mtx_rows = np.repeat(mtx_rows, n_out)\n",
    "                        # print(\"mtx_rows = {}\".format(mtx_rows))\n",
    "                        mtx_cols = np.arange(col0, col1)\n",
    "                        # print(\"mtx_cols = {}\".format(mtx_cols))\n",
    "                        mtx_cols = np.tile(mtx_cols, n_rows)\n",
    "                        # print(\"mtx_cols = {}\".format(mtx_cols))\n",
    "                        ws = weights[mtx_rows, mtx_cols].copy().reshape((n_rows, n_out))\n",
    "                        # print(ws.shape)\n",
    "                        # print(ws)\n",
    "                        # row0 = prei * size_pre\n",
    "                        # row1 = row0 + size_pre\n",
    "                        # ws = weights[row0:row1, col0:col1]\n",
    "\n",
    "                    else:\n",
    "                        pre_is_conv = False\n",
    "                        row0 = prei * size_pre\n",
    "                        row1 = row0 + size_pre\n",
    "                        ws = weights[row0:row1, :]\n",
    "\n",
    "                    # for cidx in range(ws.shape[1]):\n",
    "                    #     ws[:, cidx] = norm_w(ws[:, cidx])\n",
    "\n",
    "                    wl.append(ws)\n",
    "                    cn = sim.PoolDenseConnector(prei, pre_shape, ws, n_out, pool_area,\n",
    "                                                pool_stride, pre_is_conv=pre_is_conv)\n",
    "\n",
    "                    prj = sim.Projection(pre, post, cn, label=lbl)\n",
    "                    projs[lbl] = prj\n",
    "\n",
    "            kernels[o] = wl\n",
    "\n",
    "    sim_time = digit_duration #* (n_digits + 0.1)\n",
    "    all_neos = []\n",
    "    all_spikes = []\n",
    "    for ch_idx in range(n_digits):\n",
    "        print(\"--------------- character {} ---------------\".format(\n",
    "            ch_idx + start_char))\n",
    "        neos = {}\n",
    "        spikes = {}\n",
    "\n",
    "        sim.run(sim_time)\n",
    "\n",
    "        for k in rec:\n",
    "            neos[k] = [p.get_data() for p in pops[k]]\n",
    "            spikes[k] = [x.segments[0].spiketrains for x in neos[k]]\n",
    "\n",
    "        all_neos.append(neos)\n",
    "        all_spikes.append(spikes)\n",
    "\n",
    "        # sim.reset()\n",
    "\n",
    "        for k in pops:\n",
    "            if 'conv' in k or 'dense' in k:\n",
    "                for p in pops[k]:\n",
    "                    p.set(v=0)\n",
    "\n",
    "    sim.end()\n",
    "\n",
    "    with h5py.File(\"output_data_simple_cnn_mnist.h5\", \"a\") as h5:\n",
    "        # sim.reset()\n",
    "        smp = \"sample\"\n",
    "        tgt = \"target\"\n",
    "        rts = \"rates\"\n",
    "        nt = \"n_test\"\n",
    "        if not smp in h5:\n",
    "            gsamp = h5.create_dataset(smp, (10000, 1), dtype='int')\n",
    "            gtgt = h5.create_dataset(tgt, (10000, 1), dtype='int')\n",
    "            grts = h5.create_dataset(rts, (10000, 10), dtype='int')\n",
    "            gnt = h5.create_dataset(nt, (1,), dtype='int')\n",
    "        else:\n",
    "            gsamp = h5[smp]\n",
    "            gtgt = h5[tgt]\n",
    "            grts = h5[rts]\n",
    "            gnt = h5[nt]\n",
    "\n",
    "        for ch_idx in range(n_digits):\n",
    "            aidx = ch_idx + start_char\n",
    "            rs = [len(ts) for ts in all_spikes[ch_idx]['dense_2'][0]]\n",
    "            gnt[:] = aidx + 1\n",
    "            gsamp[aidx, 0] = aidx\n",
    "            gtgt[aidx, 0] = test_y[ch_idx]\n",
    "            grts[aidx, :] = rs\n",
    "\n",
    "            ty = test_y[ch_idx]\n",
    "            py = np.argmax(rs)\n",
    "\n",
    "            print(\"Sample {}\\tPredicted = {}\\tExpected = {}\".format(aidx, py, ty))\n",
    "\n",
    "    import plot_simple_cnn_mnist as splt\n",
    "\n",
    "    # for i, _spikes in enumerate(all_spikes):\n",
    "    prefix = \"{:03}\".format(start_char)\n",
    "#     prefix = \"{:03}\".format(0)\n",
    "    data = splt.plot_images(order, shapes, test_y, kernels, spikes,\n",
    "                            n_digits*sim_time, digit_duration, offsets, norm_w,\n",
    "                            n_digits, prefix)\n",
    "    rates, conf_mtx, correct, no_spikes = data\n",
    "#     splt.plot_matrix(conf_mtx, n_digits, no_spikes, correct, prefix)\n",
    "#     splt.plot_rates(rates, order, prefix=prefix)\n",
    "#     splt.plot_spikes(order, spikes, sim_time, digit_duration, prefix)\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc218606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      " start character index 0 \n",
      " number of characters per run 1\n",
      "=======================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-17 23:38:21 INFO: Read configs files: /home/chanokin/sussex/spike_conv_nets/SpiNNUtils/spinn_utilities/spinn_utilities.cfg, /home/chanokin/sussex/spike_conv_nets/SpiNNMachine/spinn_machine/spinn_machine.cfg, /home/chanokin/sussex/spike_conv_nets/PACMAN/pacman/pacman.cfg, /home/chanokin/sussex/spike_conv_nets/SpiNNMan/spinnman/spinnman.cfg, /home/chanokin/sussex/spike_conv_nets/DataSpecification/data_specification/data_specification.cfg, /home/chanokin/sussex/spike_conv_nets/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg, /home/chanokin/sussex/spike_conv_nets/sPyNNaker/spynnaker/pyNN/spynnaker.cfg, /home/chanokin/.spynnaker.cfg, ./spynnaker.cfg\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writetextspecs has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writeenergyreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writerouterreports has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writeroutersummaryreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writecompressedroutersummaryreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writemachinegraphplacerreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writememorymapreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writedataspeedupreports has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writejsonmachine has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writejsonmachinegraph has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writejsonplacements has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writejsonroutingtables has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writejsonpartitionnkeysmap has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writecompressoriobuf has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writebitfieldcompressorreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writepacmanexecutorprovenance has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writesynapticreport has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writenetworkgraph has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writeexpanderiobuf has been set to True\n",
      "2021-06-17 23:38:21 INFO: As mode == \"Debug\", [Reports] writebitfieldiobuf has been set to True\n",
      "2021-06-17 23:38:21 INFO: [Reports]write_energy_report has been set to False as using virtual boards\n",
      "2021-06-17 23:38:21 INFO: [Reports]write_board_chip_report has been set to False as using virtual boards\n",
      "2021-06-17 23:38:21 INFO: Will search these locations for binaries: /home/chanokin/sussex/spike_conv_nets/SpiNNFrontEndCommon/spinn_front_end_common/common_model_binaries : /home/chanokin/sussex/spike_conv_nets/sPyNNaker/spynnaker/pyNN/model_binaries\n",
      "2021-06-17 23:38:21 WARNING: /home/chanokin/sussex/spike_conv_nets/spike_conv_nets/reports has 16 old reports that have not been closed\n",
      "2021-06-17 23:38:21 ERROR: write_synaptic_report ignored due to https://github.com/SpiNNakerManchester/sPyNNaker/issues/1081\n",
      "NoneType: None\n",
      "2021-06-17 23:38:21 INFO: Setting time scale factor to 1.\n",
      "2021-06-17 23:38:21 INFO: Setting machine time step to 1000 micro-seconds.\n",
      "2021-06-17 23:38:21 WARNING: Size of the population mnist rounded from 4096 to 4096. Please use int values for size\n",
      "/home/chanokin/sussex/spike_conv_nets/sPyNNaker/spynnaker/pyNN/models/spike_source/spike_source_poisson_vertex.py:276: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  1.0 - (1.0 / max_rates), max_rates))\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_0 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_1 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_2 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_3 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_4 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_5 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_6 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_7 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_8 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_9 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_10 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_11 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_12 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_13 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_14 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_chan_15 rounded from 760 to 760. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_0 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_1 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_2 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_3 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_4 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_5 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_6 rounded from 64 to 64. Please use int values for size\n",
      "2021-06-17 23:38:21 WARNING: Size of the population conv2d_1_chan_7 rounded from 64 to 64. Please use int values for size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/chanokin/sussex/spike_conv_nets/SpiNNUtils/spinn_utilities/spinn_utilities.cfg', '/home/chanokin/sussex/spike_conv_nets/SpiNNMachine/spinn_machine/spinn_machine.cfg', '/home/chanokin/sussex/spike_conv_nets/PACMAN/pacman/pacman.cfg', '/home/chanokin/sussex/spike_conv_nets/SpiNNMan/spinnman/spinnman.cfg', '/home/chanokin/sussex/spike_conv_nets/DataSpecification/data_specification/data_specification.cfg', '/home/chanokin/sussex/spike_conv_nets/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg', '/home/chanokin/sussex/spike_conv_nets/sPyNNaker/spynnaker/pyNN/spynnaker.cfg', '/home/chanokin/.spynnaker.cfg', './spynnaker.cfg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-17 23:38:22 INFO: Starting execution process\n",
      "2021-06-17 23:38:22 INFO: Simulating for 500 1.0ms timesteps using a hardware timestep of 1000us\n",
      "2021-06-17 23:38:22 WARNING: For virtual Machines version is deprecated.use width=2, height=2 instead\n",
      "2021-06-17 23:38:22 INFO: Created a virtual machine which has 72 cores and 8.0 links\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.002895 taken by VirtualMachineGenerator\n",
      "Preallocating resources for Extra Monitor support vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.006836 taken by PreAllocateResourcesForExtraMonitorSupport\n",
      "generating the graphical representation of the neural network\n",
      "|0%                          50%                         100%|\n",
      " =========================================================="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- character 0 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.756988 to fit\n",
      "==\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.509895 taken by SpYNNakerNeuronGraphNetworkSpecificationReport\n",
      "Converting to JSON machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.005016 taken by WriteJsonMachine\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.004906 taken by NetworkSpecificationReport\n",
      "Allocating virtual identifiers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.011673 taken by MallocBasedChipIDAllocator\n",
      "Adding Splitter selectors where appropriate\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.018466 taken by SpynnakerSplitterSelector\n",
      "Adding delay extensions as required\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:22 INFO: Time 0:00:00.012810 taken by DelaySupportAdder\n",
      "Partitioning graph vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Partitioning graph edges\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:01.148740 taken by SpYNNakerSplitterPartitioner\n",
      "Inserting extra monitors into graphs\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.010919 taken by InsertExtraMonitorVerticesToGraphs\n",
      "Generating partitioner report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.009283 taken by PartitionerReport\n",
      "Converting to JSON MachineGraph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.023362 taken by WriteJsonMachineGraph\n",
      "Getting number of keys required by each edge using application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.020091 taken by EdgeToNKeysMapper\n",
      "2021-06-17 23:38:23 INFO: The time scale factor could be reduced to 0.5\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.002028 taken by LocalTDMABuilder\n",
      "Converting to JSON partition n key map\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.006659 taken by WriteJsonPartitionNKeysMap\n",
      "Placing graph vertices via spreading over an entire machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.008313 taken by SpreaderPlacer\n",
      "Inserting edges between vertices which require FR speed up functionality.\n",
      "|0%                          50%                         100%|\n",
      " ======================================2021-06-17 23:38:23 INFO: Time 0:00:00.014944 taken by InsertEdgesToExtraMonitorFunctionality\n",
      "Generating routing tables for data in system processes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:23 INFO: Time 0:00:00.003628 taken by SystemMulticastRoutingGenerator\n",
      "Generating fixed router routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.002290 taken by FixedRouteRouter\n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.015152 taken by PlacerReportWithApplicationGraph\n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.031661 taken by PlacerReportWithoutApplicationGraph\n",
      "Converting to JSON Placements\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.007167 taken by WriteJsonPlacements\n",
      "Routing\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.025567 taken by NerRouteTrafficAware\n",
      "Discovering tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.015465 taken by BasicTagAllocator\n",
      "Reporting Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.002095 taken by TagReport\n",
      "Getting constraints for machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.036674 taken by ProcessPartitionConstraints\n",
      "Calculating zones\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating routing keys\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.018561 taken by ZonedRoutingInfoAllocator\n",
      "Generating Routing info report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.007491 taken by routingInfoReports\n",
      "Generating routing tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.002587 taken by BasicRoutingTableGenerator\n",
      "Generating Routing path report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.022982 taken by RouterReports\n",
      "Generating Routing summary report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.003376 taken by RouterSummaryReport\n",
      "Converting to JSON RouterTables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.008068 taken by WriteJsonRoutingTables\n",
      "Compressing routing Tables using PairCompressor\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:24 INFO: Time 0:00:00.002338 taken by PairCompressor\n",
      "Generating data specifications\n",
      "|0%                          50%                         100%|\n",
      " ==================================================/home/chanokin/sussex/spike_conv_nets/sPyNNaker/spynnaker/pyNN/models/spike_source/spike_source_poisson_machine_vertex.py:423: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (1.0 / spikes_per_tick).astype(int), 0).astype(\"uint32\")\n",
      "==========\n",
      "2021-06-17 23:38:28 INFO: Time 0:00:03.961275 taken by SpynnakerDataSpecificationWriter\n",
      "2021-06-17 23:38:28 INFO: Running for 1 steps for a total of 500.0ms\n",
      "2021-06-17 23:38:28 INFO: Run 1 of 1\n",
      "2021-06-17 23:38:28 WARNING: Application will not actually be run as on a virtual board\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:28 INFO: Time 0:00:00.027707 taken by SdramUsageReportPerChip\n",
      "2021-06-17 23:38:28 INFO: Time 0:00:00.051765 taken by DatabaseInterface\n",
      "Getting provenance data from machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-17 23:38:28 INFO: Time 0:00:00.046885 taken by GraphProvenanceGatherer\n",
      "2021-06-17 23:38:28 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:29 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: The simulation is using a virtual machine and so has not truly ran, hence the spike list will be empty\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-17 23:38:30 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\tPredicted = 0\tExpected = 1\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes -1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_char = 0\n",
    "n_digits = 1\n",
    "n_test = 1\n",
    "scale = 1.0\n",
    "print(\n",
    "    \"=======================================================\"\n",
    "    \"\\n start character index {} \"\n",
    "    \"\\n number of characters per run {}\"\n",
    "    \"\\n=======================================================\\n\\n\".format(\n",
    "        start_char, n_digits))\n",
    "run_network(start_char, n_digits, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08903241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv3",
   "language": "python",
   "display_name": "venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}