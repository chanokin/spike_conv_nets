{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b11994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import spynnaker8 as sim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "import field_encoding as fe\n",
    "from field_encoding import ROWS_AS_MSB\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2773d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(start_char, n_digits, n_test=10000, scale=1.0):\n",
    "\n",
    "    most_significant_rows = ROWS_AS_MSB\n",
    "\n",
    "    filename = \"simple_cnn_network_elements.npz\"\n",
    "\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    thresholds = dict(\n",
    "        conv2d=1,#3.1836495399475098,\n",
    "        conv2d_1=1,#2.9346282482147217,\n",
    "        dense=1,#1.1361589431762695,\n",
    "        dense_1=1,#2.435835599899292,\n",
    "        dense_2=1,#2.36885929107666,\n",
    "    )\n",
    "\n",
    "    order0 = data['order']\n",
    "    order = order0[:]\n",
    "    ml_conns = data['conns'].item()\n",
    "    ml_param = data['params'].item()\n",
    "\n",
    "    # print(list(data.keys()))\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "#     random_state = check_random_state(0)\n",
    "#     permutation = random_state.permutation(X.shape[0])\n",
    "#     X = X[permutation]\n",
    "#     y = y[permutation]\n",
    "    X = X.reshape((X.shape[0], -1))\n",
    "    \n",
    "    train_samples = 5000\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                X, y, train_size=train_samples, test_size=10000)\n",
    "    \n",
    "    \n",
    "\n",
    "    test_X_0 = X_test[start_char: start_char + n_digits]\n",
    "    test_y = y_test[start_char: start_char + n_digits]\n",
    "    \n",
    "    w = 32\n",
    "    shape_in = np.asarray([w, w])\n",
    "    shapes = {'input': shape_in}\n",
    "    orig_shape = [28, 28]\n",
    "    test_X = []\n",
    "    for i, x in enumerate(test_X_0):\n",
    "#         image_resized = resize(image, (image.shape[0] // 4, image.shape[1] // 4),\n",
    "#                        anti_aliasing=True)\n",
    "        x = x.reshape(orig_shape)\n",
    "        x = resize(x, shape_in, anti_aliasing=True)\n",
    "        test_X.append(x)\n",
    "        \n",
    "    # shape of dataset\n",
    "    # print('X_test:  ' + str(test_X.shape))\n",
    "    # print('Y_test:  ' + str(test_y.shape))\n",
    "\n",
    "    # plotting\n",
    "    # for i in range(9):\n",
    "    #     plt.subplot(330 + 1 + i)\n",
    "    #     plt.imshow(test_X[i], cmap=plt.get_cmap('gray'))\n",
    "    #\n",
    "    # plt.show()\n",
    "\n",
    "    MAX_N_DENSE = 100\n",
    "    MAX_N_CONV = 512\n",
    "    # sim.extra_models.SpikeSourcePoissonVariable.set_model_max_atoms_per_core(512)\n",
    "    sim.IF_curr_exp_conv.set_model_max_atoms_per_core(MAX_N_CONV)\n",
    "    sim.NIF_curr_exp_conv.set_model_max_atoms_per_core(MAX_N_CONV)\n",
    "    # sim.IF_curr_exp_conv.set_model_max_atoms_per_core(n_atoms=256)\n",
    "    sim.IF_curr_exp_pool_dense.set_model_max_atoms_per_core(MAX_N_DENSE)\n",
    "    sim.NIF_curr_exp_pool_dense.set_model_max_atoms_per_core(MAX_N_DENSE)\n",
    "\n",
    "    sim.setup(timestep=1.)\n",
    "\n",
    "    np.random.seed(13)\n",
    "\n",
    "    # shapes are specified as Height, Width == Rows, Columns\n",
    "    n_in = int(np.prod(shape_in))\n",
    "    in_ids = np.arange(0, n_in)\n",
    "    n_in = fe.max_coord_size(shape=shape_in, most_significant_rows=ROWS_AS_MSB)\n",
    "    xy_in_ids = fe.convert_ids(in_ids, shape=shape_in, most_significant_rows=ROWS_AS_MSB)\n",
    "\n",
    "    digit_duration = 500.0  # ms\n",
    "    digit_rate = 100.0  # hz\n",
    "    in_rates = np.zeros((n_in, n_digits))\n",
    "    for i in range(n_digits):\n",
    "        in_rates[xy_in_ids, i] = test_X[i].flatten()\n",
    "\n",
    "    in_rates *= (digit_rate / in_rates.max())\n",
    "    in_durations = np.ones((n_in, n_digits)) * np.round(digit_duration * 0.9)\n",
    "    in_starts = np.repeat([np.arange(n_digits) * digit_duration],\n",
    "                          n_in, axis=0)\n",
    "    in_params = {\n",
    "        'rates': in_rates,\n",
    "        'starts': in_starts,\n",
    "        'durations': in_durations\n",
    "    }\n",
    "    pops = {\n",
    "        'input': [sim.Population(  # put into list for ease of connection\n",
    "            n_in,  # number of sources\n",
    "            sim.extra_models.SpikeSourcePoissonVariable,  # source type\n",
    "            in_params,\n",
    "            label='mnist',\n",
    "            additional_parameters={'seed': 24534}\n",
    "        )]\n",
    "    }\n",
    "    sizes = {'input': [p.size for p in pops['input']]}\n",
    "\n",
    "    # ------------------------------------------------------------------- #\n",
    "    # ------------------------------------------------------------------- #\n",
    "    def_params = {\n",
    "        'v_thresh': 1.,\n",
    "        'v_reset': 0.,\n",
    "        'v': 0.,\n",
    "        # 'v_rest': 0.,\n",
    "        # 'tau_m': 10.,\n",
    "        # 'cm': 0.80,\n",
    "    }\n",
    "    local_thresh = bool(0)\n",
    "    use_lif = bool(0)\n",
    "    conv_cell_type = sim.IF_curr_exp_conv if use_lif else sim.NIF_curr_exp_conv\n",
    "    dense_cell_type = sim.IF_curr_exp_pool_dense if use_lif else sim.NIF_curr_exp_pool_dense\n",
    "    pre_shapes = [shape_in]\n",
    "    for i, o in enumerate(order):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        o0 = order[i - 1]\n",
    "        pre_shape = pre_shapes[i - 1]\n",
    "        par = ml_param[o]\n",
    "        if 'conv2d' in o.lower():\n",
    "            c = ml_conns[o]\n",
    "            kernel_shape = c['weights'].shape[:2]\n",
    "            pooling = 'pool' in c\n",
    "            pool_area = np.asarray(c['pool']['shape']) if pooling else None\n",
    "            pool_stride = np.asarray(c['pool']['strides']) if pooling else None\n",
    "            wshape = c.get('shape', None)\n",
    "            strides = c.get('strides', None)\n",
    "            shape = sim.ConvolutionConnector.calculate_post_shape(\n",
    "                            pre_shape, kernel_shape, \n",
    "                            padding=np.array([0, 0]), \n",
    "                            stride=strides, \n",
    "                            pooling=pooling, \n",
    "                            pool_shape=pool_area, \n",
    "                            pool_stride=pool_stride)\n",
    "            pre_shapes.append(shape)\n",
    "            shapes[o] = shape\n",
    "            \n",
    "#             shape = par['shape'][0:2]\n",
    "            chans = par['shape'][2]\n",
    "            ps = def_params.copy()\n",
    "            v = ps.pop('v')\n",
    "            ps['v_thresh'] = thresholds[o] if local_thresh else par['threshold']\n",
    "            n = int(np.prod(shape))\n",
    "            n = fe.max_coord_size(shape=shape, most_significant_rows=ROWS_AS_MSB)\n",
    "            # print(o, n, shape, chans)\n",
    "            pop = [sim.Population(n, conv_cell_type, ps,\n",
    "                                  label=\"{}_chan_{}\".format(o, ch))\n",
    "                   for ch in range(chans)]\n",
    "\n",
    "            for p in pop:\n",
    "                p.set(v=v)\n",
    "        elif 'dense' in o.lower():\n",
    "            shape = par['shape'][0:2]\n",
    "            pre_shapes.append(shape)\n",
    "            shapes[o] = shape\n",
    "            ps = def_params.copy()\n",
    "            v = ps.pop('v')\n",
    "            ps['v_thresh'] = thresholds[o] if local_thresh else par['threshold']\n",
    "\n",
    "            # TODO: should this be converted to XY encoding as well?\n",
    "            #       at this point I think any topology is lost\n",
    "            n = int(np.prod(shape))\n",
    "            chans = 1\n",
    "            # TODO: Before I was manually splitting the flatten / dense\n",
    "            #       region. Hopefully, with the automatic splitting, we can\n",
    "            #       get all the network to fit in the small board\n",
    "            # if 'conv2d' in order[i-1]:\n",
    "            #     chans = 4\n",
    "            #     n = n // chans\n",
    "\n",
    "            pop = [sim.Population(n, dense_cell_type, ps,\n",
    "                                  label=\"{}_chan_{}\".format(o, ch))\n",
    "                   for ch in range(chans)]\n",
    "            for p in pop:\n",
    "                p.set(v=v)\n",
    "\n",
    "        sizes[o] = [p.size for p in pop]\n",
    "        pops[o] = pop\n",
    "\n",
    "    rec = [\n",
    "        'input',\n",
    "        'conv2d',\n",
    "        'conv2d_1',\n",
    "        'dense',\n",
    "        'dense_1',\n",
    "        'dense_2',\n",
    "    ]\n",
    "\n",
    "#     shapes = {\n",
    "#         'input': [28, 28],\n",
    "#         'conv2d': [24, 24],\n",
    "#         'conv2d_1': [8, 8],\n",
    "#         'dense': [12, 12],\n",
    "#         'dense_1': [8, 8],\n",
    "#         'dense_2': [4, 4],\n",
    "#     }\n",
    "\n",
    "    offsets = {\n",
    "        'input': 0,\n",
    "        'conv2d': 0,\n",
    "        'conv2d_1': 0,\n",
    "        'dense': 32,\n",
    "        'dense_1': 0,\n",
    "        'dense_2': 0,\n",
    "    }\n",
    "\n",
    "    for k in rec:\n",
    "        for p in pops[k][:]:\n",
    "            p.record('spikes')\n",
    "\n",
    "    projs = {}\n",
    "    kernels = {}\n",
    "    dense_weights = {}\n",
    "\n",
    "    def norm_w(w, is_conv=False, trans=None):\n",
    "        new_w = w.copy()\n",
    "        if trans == 'linear':\n",
    "            max_w = np.max(np.abs(w))\n",
    "            new_w /= max_w\n",
    "        elif trans == 'sum_to_0':\n",
    "            pos = w[w > 0]\n",
    "            pos /= np.sum(pos)\n",
    "            neg = w[w < 0]\n",
    "            neg /= (-np.sum(neg))\n",
    "            new_w = w.copy()\n",
    "            new_w[w > 0] = pos\n",
    "            new_w[w < 0] = neg\n",
    "        elif trans == 'mean_var':\n",
    "            v = new_w.var()\n",
    "            new_w -= new_w.mean()\n",
    "            new_w /= v\n",
    "\n",
    "        return new_w\n",
    "\n",
    "#     shapes = {}\n",
    "    for i, o in enumerate(order):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        c = ml_conns[o]\n",
    "        weights = c['weights']\n",
    "        pooling = 'pool' in c\n",
    "        pool_area = np.asarray(c['pool']['shape']) if pooling else None\n",
    "        pool_stride = np.asarray(c['pool']['strides']) if pooling else None\n",
    "        wshape = c.get('shape', None)\n",
    "        strides = c.get('strides', None)\n",
    "        pre_shape = pre_shapes[i - 1]\n",
    "        print(\"layer {}, pre shape is {}\".format(o, pre_shape))\n",
    "        o0 = order[i - 1]\n",
    "        # dense_weights[o] =\n",
    "        pops0 = pops[o0]\n",
    "        pops1 = pops[o]\n",
    "        # print(o0, o)\n",
    "        for prei, pre in enumerate(pops0):\n",
    "#             pre_shape = np.asarray(ml_param[o0]['shape'][:2])\n",
    "\n",
    "            if len(pre_shape) == 1:\n",
    "                pre_shape = (1, pre.size)\n",
    "                n_chan = 1\n",
    "            else:\n",
    "                n_chan = ml_param[o0]['shape'][-1]\n",
    "\n",
    "            wl = []\n",
    "            for posti, post in enumerate(pops1):\n",
    "                lbl = \"{}_{} to {}_{}\".format(o0, prei, o, posti)\n",
    "                # print(pre_shape, n_chan, o0, prei, o, posti)\n",
    "                if 'conv2d' in o.lower():\n",
    "                    # print(prei, posti, wshape, c['weights'].shape)\n",
    "                    w = norm_w(weights[:, :, prei, posti].copy())\n",
    "                    # note we need to flip kernels for the operation to be a\n",
    "                    # convolution instead of a correlation\n",
    "                    w = np.flipud(np.fliplr(w))\n",
    "                    wl.append(w)\n",
    "                    cn = sim.ConvolutionConnector(pre_shape, w, strides=strides,\n",
    "                            pooling=pool_area, pool_stride=pool_stride,\n",
    "                            most_significant_rows=most_significant_rows)\n",
    "                    prj = sim.Projection(pre, post, cn, label=lbl)\n",
    "                    projs[lbl] = prj\n",
    "\n",
    "                elif 'dense' in o.lower():\n",
    "                    n_out = post.size\n",
    "                    sh_pre = sim.PoolDenseConnector.calc_post_pool_shape(\n",
    "                                pre_shape, pooling, pool_area, pool_stride)\n",
    "                    size_pre = int(np.prod(sh_pre))\n",
    "                    if 'conv2d' in o0.lower():\n",
    "                        pre_is_conv = True\n",
    "                        cnv = pops[o0]\n",
    "                        col0 = posti * n_out\n",
    "                        col1 = col0 + n_out\n",
    "\n",
    "                        mtx_rows = []\n",
    "                        chan = prei\n",
    "                        for r in np.arange(sh_pre[0]):\n",
    "                            for c in np.arange(sh_pre[1]):\n",
    "                                mtx_rows.append(r * sh_pre[1] * len(pops[o0]) +\n",
    "                                                c * len(pops[o0]) + chan)\n",
    "                        mtx_rows = np.asarray(mtx_rows)\n",
    "                        pre_rows = np.repeat(np.arange(sh_pre[0]), sh_pre[1])\n",
    "                        # print(\"pre_rows = {}\".format(pre_rows))\n",
    "                        pre_cols = np.tile(np.arange(sh_pre[1]), sh_pre[0])\n",
    "                        # print(\"pre_cols = {}\".format(pre_cols))\n",
    "                        mtx_rows0 = (pre_rows * sh_pre[1] * n_chan +\n",
    "                                     pre_cols * n_chan + prei)\n",
    "                        # print(\"mtx_rows = {}\".format(mtx_rows))\n",
    "                        # print(np.all(mtx_rows == mtx_rows0))\n",
    "                        n_rows = len(mtx_rows)\n",
    "                        mtx_rows = np.repeat(mtx_rows, n_out)\n",
    "                        # print(\"mtx_rows = {}\".format(mtx_rows))\n",
    "                        mtx_cols = np.arange(col0, col1)\n",
    "                        # print(\"mtx_cols = {}\".format(mtx_cols))\n",
    "                        mtx_cols = np.tile(mtx_cols, n_rows)\n",
    "                        # print(\"mtx_cols = {}\".format(mtx_cols))\n",
    "#                         ws = weights[mtx_rows, mtx_cols].copy().reshape((n_rows, n_out))\n",
    "                        ws = np.arange(n_rows * n_out).reshape((n_rows, n_out)) * (5./(n_rows * n_out))\n",
    "#                         ws = np.random.uniform(0, 1, size=(n_rows, n_out))\n",
    "                        # print(ws.shape)\n",
    "                        # print(ws)\n",
    "                        # row0 = prei * size_pre\n",
    "                        # row1 = row0 + size_pre\n",
    "                        # ws = weights[row0:row1, col0:col1]\n",
    "\n",
    "                    else:\n",
    "                        pre_is_conv = False\n",
    "                        row0 = prei * size_pre\n",
    "                        row1 = row0 + size_pre\n",
    "#                         ws = weights[row0:row1, :]\n",
    "                        ws = np.arange(size_pre * n_out).reshape((size_pre, n_out)) * (5./(size_pre * n_out))\n",
    "\n",
    "#                         ws = np.random.uniform(0, 1, size=(size_pre, n_out))\n",
    "\n",
    "                    # for cidx in range(ws.shape[1]):\n",
    "                    #     ws[:, cidx] = norm_w(ws[:, cidx])\n",
    "\n",
    "                    wl.append(ws)\n",
    "                    cn = sim.PoolDenseConnector(prei, pre_shape, ws, n_out, pool_area,\n",
    "                                                pool_stride, pre_is_conv=pre_is_conv)\n",
    "\n",
    "                    prj = sim.Projection(pre, post, cn, label=lbl)\n",
    "                    projs[lbl] = prj\n",
    "\n",
    "            kernels[o] = wl\n",
    "\n",
    "    sim_time = digit_duration #* (n_digits + 0.1)\n",
    "    all_neos = []\n",
    "    all_spikes = []\n",
    "    for ch_idx in range(n_digits):\n",
    "        print(\"--------------- character {} ---------------\".format(\n",
    "            ch_idx + start_char))\n",
    "        neos = {}\n",
    "        spikes = {}\n",
    "\n",
    "        sim.run(sim_time)\n",
    "\n",
    "        for k in rec:\n",
    "            neos[k] = [p.get_data() for p in pops[k]]\n",
    "            spikes[k] = [x.segments[0].spiketrains for x in neos[k]]\n",
    "\n",
    "        all_neos.append(neos)\n",
    "        all_spikes.append(spikes)\n",
    "\n",
    "        # sim.reset()\n",
    "\n",
    "        for k in pops:\n",
    "            if 'conv' in k or 'dense' in k:\n",
    "                for p in pops[k]:\n",
    "                    p.set(v=0)\n",
    "\n",
    "    sim.end()\n",
    "\n",
    "    with h5py.File(\"output_data_simple_cnn_mnist.h5\", \"a\") as h5:\n",
    "        # sim.reset()\n",
    "        smp = \"sample\"\n",
    "        tgt = \"target\"\n",
    "        rts = \"rates\"\n",
    "        nt = \"n_test\"\n",
    "        if not smp in h5:\n",
    "            gsamp = h5.create_dataset(smp, (10000, 1), dtype='int')\n",
    "            gtgt = h5.create_dataset(tgt, (10000, 1), dtype='int')\n",
    "            grts = h5.create_dataset(rts, (10000, 10), dtype='int')\n",
    "            gnt = h5.create_dataset(nt, (1,), dtype='int')\n",
    "        else:\n",
    "            gsamp = h5[smp]\n",
    "            gtgt = h5[tgt]\n",
    "            grts = h5[rts]\n",
    "            gnt = h5[nt]\n",
    "\n",
    "        for ch_idx in range(n_digits):\n",
    "            aidx = ch_idx + start_char\n",
    "            rs = [len(ts) for ts in all_spikes[ch_idx]['dense_2'][0]]\n",
    "            gnt[:] = aidx + 1\n",
    "            gsamp[aidx, 0] = aidx\n",
    "            gtgt[aidx, 0] = test_y[ch_idx]\n",
    "            grts[aidx, :] = rs\n",
    "\n",
    "            ty = test_y[ch_idx]\n",
    "            py = np.argmax(rs)\n",
    "\n",
    "            print(\"Sample {}\\tPredicted = {}\\tExpected = {}\".format(aidx, py, ty))\n",
    "\n",
    "    import plot_simple_cnn_mnist as splt\n",
    "\n",
    "    # for i, _spikes in enumerate(all_spikes):\n",
    "    prefix = \"{:03}\".format(start_char)\n",
    "#     prefix = \"{:03}\".format(0)\n",
    "    data = splt.plot_images(order, shapes, test_y, kernels, spikes,\n",
    "                            n_digits*sim_time, digit_duration, offsets, norm_w,\n",
    "                            n_digits, prefix)\n",
    "    rates, conf_mtx, correct, no_spikes = data\n",
    "#     splt.plot_matrix(conf_mtx, n_digits, no_spikes, correct, prefix)\n",
    "#     splt.plot_rates(rates, order, prefix=prefix)\n",
    "#     splt.plot_spikes(order, spikes, sim_time, digit_duration, prefix)\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc218606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      " start character index 0 \n",
      " number of characters per run 1\n",
      "=======================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-22 23:08:20 INFO: Read configs files: /home/bbpnrsoa/convnets/SpiNNUtils/spinn_utilities/spinn_utilities.cfg, /home/bbpnrsoa/convnets/SpiNNMachine/spinn_machine/spinn_machine.cfg, /home/bbpnrsoa/convnets/PACMAN/pacman/pacman.cfg, /home/bbpnrsoa/convnets/SpiNNMan/spinnman/spinnman.cfg, /home/bbpnrsoa/convnets/DataSpecification/data_specification/data_specification.cfg, /home/bbpnrsoa/convnets/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg, /home/bbpnrsoa/convnets/sPyNNaker/spynnaker/pyNN/spynnaker.cfg, /home/bbpnrsoa/.spynnaker.cfg, ./spynnaker.cfg\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writetextspecs has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writeenergyreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writerouterreports has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writeroutersummaryreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writecompressedroutersummaryreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writemachinegraphplacerreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writememorymapreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writedataspeedupreports has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writejsonmachine has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writejsonmachinegraph has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writejsonplacements has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writejsonroutingtables has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writejsonpartitionnkeysmap has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writecompressoriobuf has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writebitfieldcompressorreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writepacmanexecutorprovenance has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writesynapticreport has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writenetworkgraph has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writeexpanderiobuf has been set to True\n",
      "2021-06-22 23:08:20 INFO: As mode == \"Debug\", [Reports] writebitfieldiobuf has been set to True\n",
      "2021-06-22 23:08:20 INFO: Will search these locations for binaries: /home/bbpnrsoa/convnets/SpiNNFrontEndCommon/spinn_front_end_common/common_model_binaries : /home/bbpnrsoa/convnets/sPyNNaker/spynnaker/pyNN/model_binaries\n",
      "2021-06-22 23:08:20 WARNING: /home/bbpnrsoa/convnets/spike_conv_nets/reports has 23 old reports that have not been closed\n",
      "2021-06-22 23:08:20 ERROR: write_synaptic_report ignored due to https://github.com/SpiNNakerManchester/sPyNNaker/issues/1081\n",
      "NoneType: None\n",
      "2021-06-22 23:08:20 INFO: Setting time scale factor to 1.\n",
      "2021-06-22 23:08:20 INFO: Setting machine time step to 1000 micro-seconds.\n",
      "2021-06-22 23:08:20 WARNING: Size of the population mnist rounded from 1024 to 1024. Please use int values for size\n",
      "/home/bbpnrsoa/convnets/sPyNNaker/spynnaker/pyNN/models/spike_source/spike_source_poisson_vertex.py:276: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  1.0 - (1.0 / max_rates), max_rates))\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_0 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_1 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_2 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_3 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_4 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_5 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_6 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_7 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_8 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_9 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_10 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_11 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_12 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_13 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_14 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_chan_15 rounded from 892 to 892. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_0 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_1 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_2 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_3 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_4 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_5 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_6 rounded from 154 to 154. Please use int values for size\n",
      "2021-06-22 23:08:20 WARNING: Size of the population conv2d_1_chan_7 rounded from 154 to 154. Please use int values for size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/bbpnrsoa/convnets/SpiNNUtils/spinn_utilities/spinn_utilities.cfg', '/home/bbpnrsoa/convnets/SpiNNMachine/spinn_machine/spinn_machine.cfg', '/home/bbpnrsoa/convnets/PACMAN/pacman/pacman.cfg', '/home/bbpnrsoa/convnets/SpiNNMan/spinnman/spinnman.cfg', '/home/bbpnrsoa/convnets/DataSpecification/data_specification/data_specification.cfg', '/home/bbpnrsoa/convnets/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg', '/home/bbpnrsoa/convnets/sPyNNaker/spynnaker/pyNN/spynnaker.cfg', '/home/bbpnrsoa/.spynnaker.cfg', './spynnaker.cfg']\n",
      "layer conv2d, pre shape is [32 32]\n",
      "layer conv2d_1, pre shape is [28 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-22 23:08:21 INFO: Starting execution process\n",
      "2021-06-22 23:08:21 INFO: Simulating for 500 1.0ms timesteps using a hardware timestep of 1000us\n",
      "Adding Splitter selectors where appropriate\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:08:21 INFO: Time 0:00:00.020427 taken by SpynnakerSplitterSelector\n",
      "Adding delay extensions as required\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:08:21 INFO: Time 0:00:00.020230 taken by DelaySupportAdder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer dense, pre shape is [10 10]\n",
      "layer dense_1, pre shape is (128,)\n",
      "layer dense_2, pre shape is (64,)\n",
      "--------------- character 0 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-22 23:08:24 INFO: Time 0:00:03.012972 taken by SpallocMaxMachineGenerator\n",
      "Preallocating resources for chip power monitor\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:08:32 INFO: Time 0:00:08.325213 taken by PreAllocateResourcesForChipPowerMonitor\n",
      "Preallocating resources for Extra Monitor support vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:08:41 INFO: Time 0:00:08.616648 taken by PreAllocateResourcesForExtraMonitorSupport\n",
      "Partitioning graph vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Partitioning graph edges\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:08:48 INFO: Time 0:00:07.115032 taken by SpYNNakerSplitterPartitioner\n",
      "Created spalloc job 6024082\n",
      "2021-06-22 23:08:48 INFO: Created spalloc job 6024082\n",
      "Waiting for board power commands to complete.\n",
      "2021-06-22 23:08:48 INFO: Waiting for board power commands to complete.\n",
      "2021-06-22 23:08:53 INFO: Time 0:00:05.049628 taken by SpallocAllocator\n",
      "2021-06-22 23:08:53 INFO: Creating transceiver for 10.11.197.129\n",
      "2021-06-22 23:08:53 INFO: Working out if machine is booted\n",
      "2021-06-22 23:08:57 INFO: Attempting to boot machine\n",
      "2021-06-22 23:09:03 INFO: Found board with version [Version: SC&MP 3.4.1 at SpiNNaker:0:0:0 (built Thu Feb 11 15:36:44 2021)]\n",
      "2021-06-22 23:09:03 INFO: Machine communication successful\n",
      "2021-06-22 23:09:03 INFO: Detected a machine on IP address 10.11.197.129 which has 856 cores and 120.0 links\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:09.939084 taken by MachineGenerator\n",
      "generating the graphical representation of the neural network\n",
      "|0%                          50%                         100%|\n",
      " ==========================================================dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.600678 to fit\n",
      "==\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.558316 taken by SpYNNakerNeuronGraphNetworkSpecificationReport\n",
      "Generating partitioner report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.030740 taken by PartitionerReport\n",
      "Converting to JSON machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.021743 taken by WriteJsonMachine\n",
      "Converting to JSON MachineGraph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.025245 taken by WriteJsonMachineGraph\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.000674 taken by NetworkSpecificationReport\n",
      "Allocating virtual identifiers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:03 INFO: Time 0:00:00.037498 taken by MallocBasedChipIDAllocator\n",
      "Adding Chip power monitors to Graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.034493 taken by InsertChipPowerMonitorsToGraphs\n",
      "Inserting extra monitors into graphs\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.032450 taken by InsertExtraMonitorVerticesToGraphs\n",
      "Writing the board chip report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.007386 taken by BoardChipReport\n",
      "Getting number of keys required by each edge using application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.065462 taken by EdgeToNKeysMapper\n",
      "2021-06-22 23:09:04 INFO: The time scale factor could be reduced to 0.5\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.003560 taken by LocalTDMABuilder\n",
      "Converting to JSON partition n key map\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.012170 taken by WriteJsonPartitionNKeysMap\n",
      "Placing graph vertices via spreading over an entire machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.021074 taken by SpreaderPlacer\n",
      "Inserting edges between vertices which require FR speed up functionality.\n",
      "|0%                          50%                         100%|\n",
      " ======================================2021-06-22 23:09:04 INFO: Time 0:00:00.050926 taken by InsertEdgesToExtraMonitorFunctionality\n",
      "Generating routing tables for data in system processes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.011337 taken by SystemMulticastRoutingGenerator\n",
      "Generating fixed router routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.010029 taken by FixedRouteRouter\n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.077692 taken by PlacerReportWithApplicationGraph\n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.085033 taken by PlacerReportWithoutApplicationGraph\n",
      "Converting to JSON Placements\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.016120 taken by WriteJsonPlacements\n",
      "Routing\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.061047 taken by NerRouteTrafficAware\n",
      "Discovering tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.062196 taken by BasicTagAllocator\n",
      "Reporting Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.008137 taken by TagReport\n",
      "Getting constraints for machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.052037 taken by ProcessPartitionConstraints\n",
      "Calculating zones\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating routing keys\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.039408 taken by ZonedRoutingInfoAllocator\n",
      "Generating Routing info report\n",
      "|0%                          50%                         100%|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.021809 taken by routingInfoReports\n",
      "Generating routing tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.034266 taken by BasicRoutingTableGenerator\n",
      "Generating Routing path report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.048178 taken by RouterReports\n",
      "Generating Routing summary report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.031317 taken by RouterSummaryReport\n",
      "Converting to JSON RouterTables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.024477 taken by WriteJsonRoutingTables\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.001685 taken by RouterCollisionPotentialReport\n",
      "Finding executable start types\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.054108 taken by LocateExecutableStartType\n",
      "Initialising buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.053891 taken by BufferManagerCreator\n",
      "Allocating SDRAM for SDRAM outgoing egde partitions\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:04 INFO: Time 0:00:00.052621 taken by SDRAMOutgoingPartitionAllocator\n",
      "Generating data specifications\n",
      "|0%                          50%                         100%|\n",
      " ==========================================================/home/bbpnrsoa/convnets/sPyNNaker/spynnaker/pyNN/models/spike_source/spike_source_poisson_machine_vertex.py:423: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (1.0 / spikes_per_tick).astype(int), 0).astype(\"uint32\")\n",
      "==\n",
      "2021-06-22 23:09:09 INFO: Time 0:00:04.455074 taken by SpynnakerDataSpecificationWriter\n",
      "Preparing Routing Tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:09 INFO: Time 0:00:00.113540 taken by RoutingSetup\n",
      "Finding binaries\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:09 INFO: Time 0:00:00.049177 taken by GraphBinaryGatherer\n",
      "Running pair routing table compression on chip\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "Extracting IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:13 INFO: Time 0:00:03.501463 taken by PairOnChipRouterCompression\n",
      "Generating Router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:13 INFO: Time 0:00:00.035723 taken by unCompressedRoutingTableReports\n",
      "2021-06-22 23:09:13 INFO: Time 0:00:00.000830 taken by BitFieldCompressorReport\n",
      "loading fixed routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:13 INFO: Time 0:00:00.039222 taken by LoadFixedRoutes\n",
      "Executing data specifications and loading data for system vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:13 INFO: Time 0:00:00.170660 taken by HostExecuteSystemDataSpecification\n",
      "Loading system executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:19 INFO: Time 0:00:05.762149 taken by LoadSystemExecutableImages\n",
      "2021-06-22 23:09:19 INFO: Time 0:00:00.001529 taken by TagsFromMachineReport\n",
      "Clearing tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Loading Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:19 INFO: Time 0:00:00.025770 taken by TagsLoader\n",
      "Executing data specifications and loading data for application vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:20 INFO: Time 0:00:01.714745 taken by HostExecuteApplicationDataSpecification\n",
      "Preparing to Expand Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Expanding Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "Extracting IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-22 23:09:21 INFO: Time 0:00:00.587858 taken by SynapseExpander\n",
      "Running bitfield generation on chip\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "Extracting IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:03.531954 taken by OnChipBitFieldGenerator\n",
      "Finalising Retrieved Connections\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.054193 taken by FinishConnectionHolders\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.002805 taken by MemoryMapOnHostReport\n",
      "Writing memory map reports\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.179114 taken by MemoryMapOnHostChipReport\n",
      "Reading Routing Tables from Machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.622638 taken by ReadRoutingTablesFromMachine\n",
      "Generating compressed router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.032859 taken by compressedRoutingTableReports\n",
      "Generating comparison of router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.024399 taken by comparisonOfRoutingTablesReport\n",
      "Generating Routing summary report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:25 INFO: Time 0:00:00.027173 taken by CompressedRouterSummaryReport\n",
      "Reading Routing Tables from Machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:26 INFO: Time 0:00:00.033409 taken by RoutingTableFromMachineReport\n",
      "Writing fixed route report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:26 INFO: Time 0:00:00.044222 taken by FixedRouteFromMachineReport\n",
      "Loading executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:41 INFO: Time 0:00:15.911938 taken by LoadApplicationExecutableImages\n",
      "2021-06-22 23:09:41 INFO: Running for 1 steps for a total of 500.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-22 23:09:41 INFO: Run 1 of 1\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:42 INFO: Time 0:00:00.081819 taken by SdramUsageReportPerChip\n",
      "2021-06-22 23:09:42 WARNING: Database creating changed to True due to cfg settings\n",
      "2021-06-22 23:09:42 INFO: creating live event connection database in /home/bbpnrsoa/convnets/spike_conv_nets/reports/2021-06-22-23-08-20-827024/run_1/input_output_database.db\n",
      "Creating graph description database\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:42 INFO: Time 0:00:00.150484 taken by DatabaseInterface\n",
      "2021-06-22 23:09:42 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "2021-06-22 23:09:42 INFO: Time 0:00:00.001363 taken by CreateNotificationProtocol\n",
      "Getting provenance data from machine graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:42 INFO: Time 0:00:00.117128 taken by GraphProvenanceGatherer\n",
      "Waiting for cores to be either in PAUSED or READY state\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:42 INFO: Time 0:00:00.079407 taken by ChipRuntimeUpdater\n",
      "2021-06-22 23:09:42 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:42 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2021-06-22 23:09:42 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2021-06-22 23:09:42 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2021-06-22 23:09:42 INFO: Application started; waiting 0.6s for it to stop\n",
      "2021-06-22 23:09:43 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2021-06-22 23:09:43 INFO: Time 0:00:00.964795 taken by ApplicationRunner\n",
      "Extracting IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:45 INFO: Time 0:00:02.360717 taken by ChipIOBufExtractor\n",
      "clearing IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:45 INFO: Time 0:00:00.045769 taken by ChipIOBufClearer\n",
      "Extracting buffers from the last run\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:46 INFO: Time 0:00:00.711603 taken by BufferExtractor\n",
      "2021-06-22 23:09:46 INFO: Time 0:00:00.000157 taken by FinaliseTimingData\n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " =========================================2021-06-22 23:09:46 WARNING: On dense_1_chan_0:0:63 on 4,4,6, a maximum of 3 background tasks were queued, which can indicate a core overloading. Try increasing the time_scale_factor located within the .spynnaker.cfg file or in the pynn.setup() method.\n",
      "===================\n",
      "2021-06-22 23:09:46 INFO: Time 0:00:00.162687 taken by PlacementsProvenanceGatherer\n",
      "2021-06-22 23:09:46 INFO: Time 0:00:00.001226 taken by RedundantPacketCountReport\n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " =2021-06-22 23:09:46 WARNING: The extra monitor on 1, 2 has detected that 11 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 1, 3 has detected that 13 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 1, 4 has detected that 9 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 2, 2 has detected that 5 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 2, 3 has detected that 4 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "2021-06-22 23:09:46 WARNING: The extra monitor on 2, 4 has detected that 4 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 2, 5 has detected that 1 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "==2021-06-22 23:09:46 WARNING: The extra monitor on 3, 3 has detected that 1 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 3, 5 has detected that 4 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "==2021-06-22 23:09:46 WARNING: The extra monitor on 4, 3 has detected that 2 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 4, 4 has detected that 42826 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 4, 6 has detected that 3 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "=2021-06-22 23:09:46 WARNING: The extra monitor on 4, 7 has detected that 1 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "==2021-06-22 23:09:46 WARNING: The extra monitor on 5, 4 has detected that 2 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "==2021-06-22 23:09:46 WARNING: The extra monitor on 5, 7 has detected that 1 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "==2021-06-22 23:09:46 WARNING: The extra monitor on 6, 4 has detected that 1 packets were dumped from a core failing to take the packet. This often occurs when the executable has crashed or has not been given a multicast packet callback. It can also result from the core taking too long to process each packet. These packets were reinjected and so this number is likely an overestimate.\n",
      "========================================\n",
      "2021-06-22 23:09:46 INFO: Time 0:00:00.078596 taken by RouterProvenanceGatherer\n",
      "2021-06-22 23:09:47 INFO: Time 0:00:00.254490 taken by ComputeEnergyUsed\n",
      "2021-06-22 23:09:47 INFO: Time 0:00:00.001784 taken by EnergyProvenanceReporter\n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:47 INFO: Time 0:00:00.111076 taken by ProfileDataGatherer\n",
      "Getting spikes for mnist\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_0\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_1\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_2\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_3\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_4\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_5\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_6\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_7\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_8\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_9\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_10\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_11\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_12\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_13\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_14\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_chan_15\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_0\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_1\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_2\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_3\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_4\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_5\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_6\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for conv2d_1_chan_7\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for dense_chan_0\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for dense_1_chan_0\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Getting spikes for dense_2_chan_0\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: initializing v after run and before reset only changes the current state and will be lost after reset\n",
      "2021-06-22 23:09:50 WARNING: simulator shutdown before time_scale_factorrequested\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\tPredicted = 9\tExpected = 8\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 913\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 815\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 816\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 808\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 873\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 751\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 882\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 850\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 881\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 878\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 780\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 880\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 882\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 850\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 882\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 105\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 119\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 112\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 118\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "max_index found for spikes 117\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4fa4f8e54f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\\n=======================================================\\n\\n\".format(\n\u001b[1;32m     10\u001b[0m         start_char, n_digits))\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrun_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6d6a65dab40f>\u001b[0m in \u001b[0;36mrun_network\u001b[0;34m(start_char, n_digits, n_test, scale)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:03}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;31m#     prefix = \"{:03}\".format(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     data = splt.plot_images(order, shapes, test_y, kernels, spikes,\n\u001b[0m\u001b[1;32m    413\u001b[0m                             \u001b[0mn_digits\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msim_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             n_digits, prefix)\n",
      "\u001b[0;32m~/convnets/spike_conv_nets/plot_simple_cnn_mnist.py\u001b[0m in \u001b[0;36mplot_images\u001b[0;34m(order, shapes, test_y, kernels, spikes, sim_time, digit_duration, offsets, norm_w, n_digits, prefix)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             imgs, bins = plotting.spikes_to_images_list(\n\u001b[0m\u001b[1;32m     26\u001b[0m                                       \u001b[0mspikes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                       \u001b[0mdigit_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convnets/spike_conv_nets/plotting.py\u001b[0m in \u001b[0;36mspikes_to_images_list\u001b[0;34m(spikes_list, shape, max_t, t_bin, offset_row, merge_images)\u001b[0m\n\u001b[1;32m     52\u001b[0m                           merge_images=False):\n\u001b[1;32m     53\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspikes_to_bins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspikes_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     imgs = [__plot_binned_spikes(b, shape, offset_row * i)\n\u001b[0m\u001b[1;32m     55\u001b[0m             for i, b in enumerate(bins)]\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convnets/spike_conv_nets/plotting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m                           merge_images=False):\n\u001b[1;32m     53\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspikes_to_bins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspikes_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     imgs = [__plot_binned_spikes(b, shape, offset_row * i)\n\u001b[0m\u001b[1;32m     55\u001b[0m             for i, b in enumerate(bins)]\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convnets/spike_conv_nets/plotting.py\u001b[0m in \u001b[0;36m__plot_binned_spikes\u001b[0;34m(binned, shape, offset_row)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmax_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msbin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_augmented_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_significant_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROWS_AS_MSB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/convnets/spike_conv_nets/field_encoding/__init__.py\u001b[0m in \u001b[0;36mget_augmented_shape\u001b[0;34m(shape, most_significant_rows)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_bits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmost_significant_rows\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "start_char = 0\n",
    "n_digits = 1\n",
    "n_test = 1\n",
    "scale = 1.0\n",
    "print(\n",
    "    \"=======================================================\"\n",
    "    \"\\n start character index {} \"\n",
    "    \"\\n number of characters per run {}\"\n",
    "    \"\\n=======================================================\\n\\n\".format(\n",
    "        start_char, n_digits))\n",
    "run_network(start_char, n_digits, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08903241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f591e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv_venv3",
   "language": "python",
   "name": "conv_venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
